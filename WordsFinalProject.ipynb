{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricwikia\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pop_playlist_project.csv\")\n",
    "df.columns = ['Spotify_URI','TrackName','ArtistName','AlbumName','DiscNum','TrackNum','TrackDur','AddedBy','AddedAt']\n",
    "lyrics = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        lyrics_temp = lyricwikia.get_lyrics(df.ArtistName[i], df.TrackName[i])\n",
    "        lyrics=lyrics+lyrics_temp\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huuki\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  744578\n",
      "Total Vocab:  70\n"
     ]
    }
   ],
   "source": [
    "raw_text = lyrics.lower()\n",
    "\n",
    "# unique mapping of characters to numbers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  744558\n"
     ]
    }
   ],
   "source": [
    "seq_length = 20\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "X = X/float(n_vocab)\n",
    "\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "744558/744558 [==============================] - 1788s 2ms/step - loss: 2.5083\n",
      "Epoch 2/20\n",
      "744558/744558 [==============================] - 1887s 3ms/step - loss: 2.0498\n",
      "Epoch 3/20\n",
      "744558/744558 [==============================] - 1995s 3ms/step - loss: 1.8740\n",
      "Epoch 4/20\n",
      "744558/744558 [==============================] - 1760s 2ms/step - loss: 1.7648\n",
      "Epoch 5/20\n",
      "744558/744558 [==============================] - 1632s 2ms/step - loss: 1.6888\n",
      "Epoch 6/20\n",
      "744558/744558 [==============================] - 1635s 2ms/step - loss: 1.6315\n",
      "Epoch 7/20\n",
      "744558/744558 [==============================] - 1635s 2ms/step - loss: 1.5872\n",
      "Epoch 8/20\n",
      "744558/744558 [==============================] - 1636s 2ms/step - loss: 1.5510\n",
      "Epoch 9/20\n",
      "744558/744558 [==============================] - 1631s 2ms/step - loss: 1.5234\n",
      "Epoch 10/20\n",
      "744558/744558 [==============================] - 1629s 2ms/step - loss: 1.4970\n",
      "Epoch 11/20\n",
      "744558/744558 [==============================] - 1650s 2ms/step - loss: 1.4750\n",
      "Epoch 12/20\n",
      "744558/744558 [==============================] - 1643s 2ms/step - loss: 1.4569\n",
      "Epoch 13/20\n",
      "744558/744558 [==============================] - 1656s 2ms/step - loss: 1.4376\n",
      "Epoch 14/20\n",
      "744558/744558 [==============================] - 1668s 2ms/step - loss: 1.4232\n",
      "Epoch 15/20\n",
      "744558/744558 [==============================] - 1673s 2ms/step - loss: 1.4108\n",
      "Epoch 16/20\n",
      "744558/744558 [==============================] - 1656s 2ms/step - loss: 1.3966\n",
      "Epoch 17/20\n",
      "744558/744558 [==============================] - 1656s 2ms/step - loss: 1.3850\n",
      "Epoch 18/20\n",
      "744558/744558 [==============================] - 1655s 2ms/step - loss: 1.3735\n",
      "Epoch 19/20\n",
      "744558/744558 [==============================] - 1674s 2ms/step - loss: 1.3634\n",
      "Epoch 20/20\n",
      "744558/744558 [==============================] - 1632s 2ms/step - loss: 1.3531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0e314e160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gar love he daco\n",
      "let me knve me now\n",
      "i'm sure my noien bnd ereet them bhn't meen 'nh, i'm gonna tale the tay down\n",
      "i live, grrgver of h love you\n",
      "to ie ii a glehen\n",
      "fies ay foy it's to shek oh\n",
      "\n",
      "art h'l cecriin' out (bh hole mamday\n",
      "not me tiis temioiss and girlel put love\n",
      "\n",
      "h meed to know you know\n",
      "ht's tomeone eloss to me\n",
      "nh, yeah\n",
      "you sealldli, you cann babk down\n",
      "mafe anpne shake on your elessinn is hl toneooe io norh thene\n",
      "vh'sh sometiing iust a cream i'm aaay\n",
      "lyst meed ly herd fuasy kust giving up c doiams. loon homesw\n",
      "when you know sote youare so stnp\n",
      "shese she l waiting yith you\n",
      "shoings nucr the world butuin' op these whnl\n",
      "aut he seidn me cralid\n",
      "up eor taki\n",
      "a peteac th you cai\n",
      "apd would coie on a mistle, sul\n",
      "may mee see herpe, doyn, your lamehn anl the lovhn's cilccrest so tacrth rkokdn, noh\n",
      "hot fxehn i bll\n",
      "nn you're beiggnite me takes bhtw\n",
      "bc ttedtits, ouel it feel the heart is tp it ayas? this bnm i shene wo go, niver mefe you ceen somou\n",
      "nume so gipl i'm a geieen\n",
      "onl thmr c linltn, si\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "initial_text=\"these lyrics are for my new great rock song about iupui and these lyrics are for my new great rock song about data\"\n",
    "pattern=[char_to_int[char] for char in initial_text]\n",
    "pattern=pattern[0:seq_length]\n",
    "\n",
    "text_gen=\"\"\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    prediction = prediction[0]\n",
    "    index = numpy.random.choice(len(prediction), p=prediction)\n",
    "    result = int_to_char[index]\n",
    "    text_gen=text_gen+result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model_letter.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model_letter.h5')\n",
    "print('Saved model to disk')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open('letterDict.pickle','wb')\n",
    "pickle.dump(char_to_int,pickle_out)\n",
    "pickle_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
