{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricwikia\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pop_playlist_project.csv\")\n",
    "df.columns = ['Spotify_URI','TrackName','ArtistName','AlbumName','DiscNum','TrackNum','TrackDur','AddedBy','AddedAt']\n",
    "lyrics = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        lyrics_temp = lyricwikia.get_lyrics(df.ArtistName[i], df.TrackName[i])\n",
    "        lyrics=lyrics+lyrics_temp\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  162759\n",
      "Total Vocab:  5081\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "raw_text = lyrics.lower()\n",
    "wordList = re.sub('[^\\w]',' ',raw_text).split()\n",
    "word_list =[]\n",
    "#append to word_list to get rid of any duplicate words\n",
    "wl = [word_list.append(item) for item in wordList if item not in word_list]\n",
    "    \n",
    "    \n",
    "#chars = sorted(list(set(raw_text)))\n",
    "word_to_int = dict((c,i) for i, c in enumerate(word_list))\n",
    "\n",
    "\n",
    "\n",
    "n_words = len(wordList)\n",
    "n_vocab = len(word_list)\n",
    "print(\"Total Words: \", n_words)\n",
    "print(\"Total Vocab: \",n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  162739\n"
     ]
    }
   ],
   "source": [
    "seq_length = 20\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,n_words - seq_length,1):\n",
    "    seq_in = wordList[i:i + seq_length]\n",
    "    #seq_in = re.sub('[^\\w]',' ',seq_in).split()\n",
    "\n",
    "    seq_out = wordList[i + seq_length]\n",
    "    \n",
    "    dataX.append([word_to_int[string] for string in seq_in])\n",
    "    \n",
    "    \n",
    "    dataY.append(word_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \",n_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.00019681]\n",
      "  [0.00039362]\n",
      "  ...\n",
      "  [0.00295217]\n",
      "  [0.00314899]\n",
      "  [0.0033458 ]]\n",
      "\n",
      " [[0.00019681]\n",
      "  [0.00039362]\n",
      "  [0.00059043]\n",
      "  ...\n",
      "  [0.00314899]\n",
      "  [0.0033458 ]\n",
      "  [0.00354261]]\n",
      "\n",
      " [[0.00039362]\n",
      "  [0.00059043]\n",
      "  [0.00078725]\n",
      "  ...\n",
      "  [0.0033458 ]\n",
      "  [0.00354261]\n",
      "  [0.00373942]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.03070262]\n",
      "  [0.03089943]\n",
      "  [0.03070262]\n",
      "  ...\n",
      "  [0.03089943]\n",
      "  [0.03070262]\n",
      "  [0.03089943]]\n",
      "\n",
      " [[0.03089943]\n",
      "  [0.03070262]\n",
      "  [0.03089943]\n",
      "  ...\n",
      "  [0.03070262]\n",
      "  [0.03089943]\n",
      "  [0.03070262]]\n",
      "\n",
      " [[0.03070262]\n",
      "  [0.03089943]\n",
      "  [0.043889  ]\n",
      "  ...\n",
      "  [0.03089943]\n",
      "  [0.03070262]\n",
      "  [0.03089943]]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = numpy.reshape(dataX,(n_patterns,seq_length,1))\n",
    "X = X/float(n_vocab)\n",
    "y=np_utils.to_categorical(dataY)\n",
    "print(X)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1],X.shape[2]),return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "162739/162739 [==============================] - 786s 5ms/step - loss: 6.0926\n",
      "Epoch 2/20\n",
      "162739/162739 [==============================] - 859s 5ms/step - loss: 6.0421\n",
      "Epoch 3/20\n",
      "162739/162739 [==============================] - 860s 5ms/step - loss: 6.0445\n",
      "Epoch 4/20\n",
      "162739/162739 [==============================] - 1341s 8ms/step - loss: 6.0464\n",
      "Epoch 5/20\n",
      "162739/162739 [==============================] - 1392s 9ms/step - loss: 6.0448\n",
      "Epoch 6/20\n",
      "162739/162739 [==============================] - 552s 3ms/step - loss: 6.0469\n",
      "Epoch 7/20\n",
      "162739/162739 [==============================] - 538s 3ms/step - loss: 6.0501\n",
      "Epoch 8/20\n",
      "162739/162739 [==============================] - 539s 3ms/step - loss: 6.0508\n",
      "Epoch 9/20\n",
      "162739/162739 [==============================] - 541s 3ms/step - loss: 6.0516\n",
      "Epoch 10/20\n",
      "162739/162739 [==============================] - 547s 3ms/step - loss: 6.0522\n",
      "Epoch 11/20\n",
      "162739/162739 [==============================] - 548s 3ms/step - loss: 6.0538\n",
      "Epoch 12/20\n",
      "162739/162739 [==============================] - 536s 3ms/step - loss: 6.0552\n",
      "Epoch 13/20\n",
      "162739/162739 [==============================] - 555s 3ms/step - loss: 6.0547\n",
      "Epoch 14/20\n",
      "162739/162739 [==============================] - 538s 3ms/step - loss: 6.0571\n",
      "Epoch 15/20\n",
      "162739/162739 [==============================] - 547s 3ms/step - loss: 6.0567\n",
      "Epoch 16/20\n",
      "162739/162739 [==============================] - 550s 3ms/step - loss: 6.0570\n",
      "Epoch 17/20\n",
      "162739/162739 [==============================] - 559s 3ms/step - loss: 6.0547\n",
      "Epoch 18/20\n",
      "162739/162739 [==============================] - 548s 3ms/step - loss: 6.0561\n",
      "Epoch 19/20\n",
      "162739/162739 [==============================] - 531s 3ms/step - loss: 6.0581\n",
      "Epoch 20/20\n",
      "162739/162739 [==============================] - 542s 3ms/step - loss: 6.0569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24ce6e779b0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X,y,epochs=20,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'song', 'that', 'says', 'me', 'who', 'i', 'am', 'and', 'how', 'to', 'make', 'words', 'he', 'says', 'she', 'says', 'i']\n",
      " one to baby god she t little cha who she it it for just pullin back late sound won now now up brings slow me never cause and tell just just but red i on and to see and right on happened take keep feel i y it a oh i know this t i waiting by grab mine feel of ever ran stone with that where more i my tears as i just me that all baby where thank and go ain forget my time all but again like too smile yes home you alive my dare re it\n"
     ]
    }
   ],
   "source": [
    "int_to_word = dict((i,c) for i, c in enumerate(word_list))\n",
    "\n",
    "#start = numpy.random.randint(0,len(dataX)-1)\n",
    "#pattern = dataX[start]\n",
    "initial_text='this is a song that says me who i am and how to make words he says she says i'\n",
    "initial_text = re.sub('[^\\w]',' ',initial_text).split()\n",
    "print(initial_text)\n",
    "pattern=[word_to_int[string] for string in initial_text]\n",
    "pattern=pattern[0:seq_length]\n",
    "\n",
    "#initial_text will be our user input, here it must be about 7 chars in length(including spaces)\"\n",
    "text_gen=\"\"\n",
    "\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern,(1,len(pattern),1))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model.predict(x,verbose=0)\n",
    "    prediction = prediction[0]\n",
    "    index = numpy.random.choice(len(prediction),p=prediction)\n",
    "    #index = numpy.argmax(prediction)\n",
    "    result = int_to_word[index]\n",
    "    text_gen = text_gen +' ' + result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(text_gen)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8503/8503 [==============================] - 7s 781us/step - loss: 2.8042\n",
      "Epoch 2/10\n",
      "8503/8503 [==============================] - 7s 792us/step - loss: 2.7705\n",
      "Epoch 3/10\n",
      "8503/8503 [==============================] - 7s 771us/step - loss: 2.7209\n",
      "Epoch 4/10\n",
      "8503/8503 [==============================] - 6s 759us/step - loss: 2.6837\n",
      "Epoch 5/10\n",
      "8503/8503 [==============================] - 7s 816us/step - loss: 2.6466\n",
      "Epoch 6/10\n",
      "8503/8503 [==============================] - 7s 778us/step - loss: 2.6120\n",
      "Epoch 7/10\n",
      "8503/8503 [==============================] - 7s 840us/step - loss: 2.5862\n",
      "Epoch 8/10\n",
      "8503/8503 [==============================] - 7s 775us/step - loss: 2.5545\n",
      "Epoch 9/10\n",
      "8503/8503 [==============================] - 7s 783us/step - loss: 2.5326\n",
      "Epoch 10/10\n",
      "8503/8503 [==============================] - 7s 810us/step - loss: 2.5006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d9a2d8ae80>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10,batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee to tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou tou to\n"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "#initial_text=\"these lyrics are for my new great rock song about iupui and these lyrics are for my new great rock song about data\"\n",
    "#pattern=[char_to_int[char] for char in initial_text]\n",
    "#pattern=pattern[0:seq_length]\n",
    "\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "\n",
    "text_gen=\"\"\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    prediction = prediction[0]\n",
    "#    index = numpy.random.choice(len(prediction), p=prediction)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    text_gen=text_gen+result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
