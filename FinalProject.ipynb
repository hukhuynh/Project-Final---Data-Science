{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricwikia\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"pop_playlist_project.csv\")\n",
    "df.columns = ['Spotify_URI','TrackName','ArtistName','AlbumName','DiscNum','TrackNum','TrackDur','AddedBy','AddedAt']\n",
    "lyrics = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        lyrics_temp = lyricwikia.get_lyrics(df.ArtistName[i], df.TrackName[i])\n",
    "        lyrics=lyrics+lyrics_temp\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\caleb\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words:  162759\n",
      "Total Vocab:  5081\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "raw_text = lyrics.lower()\n",
    "wordList = re.sub('[^\\w]',' ',raw_text).split()\n",
    "word_list =[]\n",
    "#append to word_list to get rid of any duplicate words\n",
    "wl = [word_list.append(item) for item in wordList if item not in word_list]\n",
    "    \n",
    "    \n",
    "#chars = sorted(list(set(raw_text)))\n",
    "word_to_int = dict((c,i) for i, c in enumerate(word_list))\n",
    "\n",
    "\n",
    "n_words = len(wordList)\n",
    "n_vocab = len(word_list)\n",
    "print(\"Total Words: \", n_words)\n",
    "print(\"Total Vocab: \",n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  162739\n"
     ]
    }
   ],
   "source": [
    "seq_length = 20\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,n_words - seq_length,1):\n",
    "    seq_in = wordList[i:i + seq_length]\n",
    "    #seq_in = re.sub('[^\\w]',' ',seq_in).split()\n",
    "\n",
    "    seq_out = wordList[i + seq_length]\n",
    "    \n",
    "    dataX.append([word_to_int[string] for string in seq_in])\n",
    "    \n",
    "    \n",
    "    dataY.append(word_to_int[seq_out])\n",
    "    \n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \",n_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = numpy.reshape(dataX,(n_patterns,seq_length,1))\n",
    "X = X/float(n_vocab)\n",
    "y=np_utils.to_categorical(dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1],X.shape[2]),return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162739/162739 [==============================] - 389s 2ms/step - loss: 6.0900\n",
      "Epoch 2/10\n",
      "162739/162739 [==============================] - 394s 2ms/step - loss: 6.0391\n",
      "Epoch 3/10\n",
      "162739/162739 [==============================] - 392s 2ms/step - loss: 6.0413\n",
      "Epoch 4/10\n",
      "162739/162739 [==============================] - 398s 2ms/step - loss: 6.0424\n",
      "Epoch 5/10\n",
      "162739/162739 [==============================] - 404s 2ms/step - loss: 6.0444\n",
      "Epoch 6/10\n",
      "162739/162739 [==============================] - 391s 2ms/step - loss: 6.0464\n",
      "Epoch 7/10\n",
      "162739/162739 [==============================] - 382s 2ms/step - loss: 6.0474\n",
      "Epoch 8/10\n",
      "162739/162739 [==============================] - 394s 2ms/step - loss: 6.0476\n",
      "Epoch 9/10\n",
      "162739/162739 [==============================] - 385s 2ms/step - loss: 6.0495\n",
      "Epoch 10/10\n",
      "162739/162739 [==============================] - 397s 2ms/step - loss: 6.0507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c4e08b860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X,y,epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'set', 'of', 'words', 'that', 'is', 'text', 'in', 'love', 'yes', 'with', 'a', 'win', 'and', 'girl', 'finding', 'a', 'state', 'of', 'happy']\n",
      " thing we can yourself and to call gotta now gonna body you you ain inside told better feel call door sweet lord the world whatever and you sweat it the can you recognize t a i do know could memories through ain devil it t wanted all part his to by yourself break let in don person even stop you can walls we can mmm losing faced light see heart i this got could know shooting and to time na when with you the doo to down rub the become take me oh rub me dance right wrong to won\n"
     ]
    }
   ],
   "source": [
    "int_to_word = dict((i,c) for i, c in enumerate(word_list))\n",
    "\n",
    "#start = numpy.random.randint(0,len(dataX)-1)\n",
    "#pattern = dataX[start]\n",
    "initial_text='a set of words that is text in love, yes with a win and girl, finding a state of happy'\n",
    "initial_text = re.sub('[^\\w]',' ',initial_text).split()\n",
    "print(initial_text)\n",
    "pattern=[word_to_int[string] for string in initial_text]\n",
    "pattern=pattern[0:seq_length]\n",
    "\n",
    "#initial_text will be our user input, here it must be about 7 chars in length(including spaces)\"\n",
    "text_gen=\"\"\n",
    "\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern,(1,len(pattern),1))\n",
    "    x = x/float(n_vocab)\n",
    "    prediction = model.predict(x,verbose=0)\n",
    "    prediction = prediction[0]\n",
    "    index = numpy.random.choice(len(prediction),p=prediction)\n",
    "    #index = numpy.argmax(prediction)\n",
    "    result = int_to_word[index]\n",
    "    text_gen = text_gen +' ' + result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(text_gen)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "162739/162739 [==============================] - 380s 2ms/step - loss: 6.0341\n",
      "Epoch 2/10\n",
      "162739/162739 [==============================] - 372s 2ms/step - loss: 6.0396\n",
      "Epoch 3/10\n",
      "162739/162739 [==============================] - 367s 2ms/step - loss: 6.0406\n",
      "Epoch 4/10\n",
      "162739/162739 [==============================] - 390s 2ms/step - loss: 6.0404\n",
      "Epoch 5/10\n",
      "162739/162739 [==============================] - 378s 2ms/step - loss: 6.0409\n",
      "Epoch 6/10\n",
      "162739/162739 [==============================] - 393s 2ms/step - loss: 6.0405\n",
      "Epoch 7/10\n",
      "162739/162739 [==============================] - 382s 2ms/step - loss: 6.0405\n",
      "Epoch 8/10\n",
      "162739/162739 [==============================] - 390s 2ms/step - loss: 6.0416\n",
      "Epoch 9/10\n",
      "162739/162739 [==============================] - 404s 2ms/step - loss: 6.0427\n",
      "Epoch 10/10\n",
      "162739/162739 [==============================] - 405s 2ms/step - loss: 6.0434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22de3ed4f98>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=10,batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-05a26296418a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint_to_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#initial_text=\"these lyrics are for my new great rock song about iupui and these lyrics are for my new great rock song about data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#pattern=[char_to_int[char] for char in initial_text]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#pattern=pattern[0:seq_length]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chars' is not defined"
     ]
    }
   ],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "#initial_text=\"these lyrics are for my new great rock song about iupui and these lyrics are for my new great rock song about data\"\n",
    "#pattern=[char_to_int[char] for char in initial_text]\n",
    "#pattern=pattern[0:seq_length]\n",
    "\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "\n",
    "text_gen=\"\"\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    prediction = prediction[0]\n",
    "#    index = numpy.random.choice(len(prediction), p=prediction)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    text_gen=text_gen+result\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "print(text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_word.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_word.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(\"wordDict.pickle\",\"wb\")\n",
    "pickle.dump(word_to_int, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
